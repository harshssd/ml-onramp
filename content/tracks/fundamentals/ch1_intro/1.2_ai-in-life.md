---
id: fundamentals-ch1-lesson2
title: AI in Your Daily Life
duration_min: 25
prereqs: ["fundamentals-ch1-lesson1"]
tags: ["beginner","context"]
video:
  platform: youtube
  id: VIDEO_ID
  start: 30
  end: 390
widgets: []
goals:
  - Identify 6 everyday AI touchpoints
  - Recognize inputs/outputs and objective signals
quiz:
  - q: Which is a reasonable objective for a spam filter?
    options: ["Max clicks","Minimize false positives","Max time on site","Random delivery"]
    answer: 1
    explain: False positives harm user trust; precision/recall trade-offs apply.
  - q: ETA in maps mostly relies on:
    options: ["Static speed limits","Averages from the '80s","Historical + live traffic patterns","Driver mood"]
    answer: 2
    explain: Models combine historical & live signals to predict arrival time.
tasks:
  - "Pick two apps you use. For each, write: inputs, model goal, what 'good' looks like."
reflection:
  - "Where might the model get feedback (labels or proxies)?"
next: "fundamentals-ch1-lesson3"
---

## Hook
From your inbox to maps to shopping—models quietly personalize experiences.

## Concept (Plain → Precise)
**Plain:** Apps guess what helps you next.  
**Precise:** Given features \(x\), models learn \(f_\theta(x)\) to optimize a task metric (CTR, accuracy, latency, etc.).

## Six micro-cases
1) **Spam filter:** inputs (subject, sender, text) → binary label.  
2) **Search ranking:** query + doc features → relevance score.  
3) **Recommendations:** user/item/history → predicted preference.  
4) **Keyboard autocomplete:** prefix → next-token probability.  
5) **ETA:** route + traffic → time regression.  
6) **Fraud detection:** transaction features → risk score.

## Watch
[Embedded segment reinforces how models map inputs→outputs.]

## Checkpoint
(see quiz block)

## Do (5 min)
List inputs/goals for two apps you love; add a "how could this fail?" note.

## Reflect
Which objective, if pushed too far, would feel creepy or harmful?
